{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Computational Almanac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standards and conventions\n",
    "\n",
    "### Why do we use standards and conventions?\n",
    "\n",
    "Accelerates your research by reducing the number of issues you have to devote brainpower towards\n",
    "\n",
    "By establishing or using a common convention that everyone adheres to, you reduce mental\n",
    "overhead and communication errors in your team\n",
    "\n",
    "### When should you use conventions\n",
    "- When a decision is not relevant to your research question\n",
    "- If there is no clear advantage to a decision, default to convention\n",
    "\n",
    "On the flip side, conventions are good candidates for new research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version control\n",
    "\n",
    "Probably one of the most important skills to learn.\n",
    "\n",
    "Use git; Learn the basics: git add, git commit, git push, git branch, etc. Expand from there as needed. \n",
    "\n",
    "Use a web-based version control tool like GitHub, GitLab, or BitBucket (these all interface with git).\n",
    "\n",
    "#### Benefits\n",
    "- Git is freedom; you don't have to fear breaking your code (or your colleagues' code); You can always revert back to a working version.\n",
    "- You no longer have to write file names like this: final_version36_last_one_i_promise_number2.txt\n",
    "\n",
    "#### Tips\n",
    "- Make changes on a new branch; when your your code is working again, merge the branch back into the main branch\n",
    "- It's a good idea to keep your main branch as the stable/working branch\n",
    "- Make changes in small increments; this makes it easier to merge branches back into main\n",
    "- Commit often. If you make multiple changes and then your code throws an error, it is harder to determine what change caused the bug\n",
    "- Write helpful commit messages; this makes it easier to find where you need to revert to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version control on a team (GitHub, GitLab, BitBucket, etc.)\n",
    "\n",
    "So you want to add a new feature to the code or fix a bug you found? Here is a simple workflow I use for small teams:\n",
    "\n",
    "1. Open a public discussion via issues or on your team's communication channel (Slack/Teams/Discord)\n",
    "\t1. State what the problem is\n",
    "\t2. State how you want to fix it\n",
    "\t3. Get feedback\n",
    "2. Create a new local branch and switch to it: `git checkout -b mybranch`\n",
    "3. Modify the code\n",
    "4. Stage and commit your changes:\n",
    "\t1. `git add changed_file.py`\n",
    "\t2. `git commit -m \"A helpful commit message\"`\n",
    "5. Repeat step 3. and 4. as needed (you can have multiple commits on the same branch)\n",
    "6. Push your local branch to remote: `git push -u origin mybranch` (you only need `-u` to initialize the remote branch, afterwards you can just `git push`)\n",
    "7. When you are happy with your changes, open a merge/pull request\n",
    "8. Have others review your changes and make comments or suggest modifications\n",
    "9.  Incorporation your team's feedback into your changes\n",
    "10. Resolve any merge conflicts\n",
    "11. When all parties are satisfied, merge the branch to the main/master branch\n",
    "12. Delete the old branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate the boring stuff\n",
    "\n",
    "We want as much of our brain power as possible going towards our research question, so questions like \"should I use tabs or spaces?\", \"How many characters long should my lines be?\" take up a small (but significant) amount of mental time and energy. Therefore, you should try to automate these trivial (but repetitive) tasks.\n",
    "\n",
    "Automation tools\n",
    "\n",
    "- Code formatting: black, autopep8\n",
    "- Linting/type checking: mypy, ruff\n",
    "- Testing: pytest\n",
    "- Documentation: sphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming\n",
    "\n",
    "Choose a style and stick to it: e.g., snake_case, CamelCase, etc. Different languages will have different standards (e.g., Python uses snake_case for functions and variables and CamelCase for classes).\n",
    "\n",
    "One convention (of many) is:\n",
    "- Variable/class names should describe what they are.\n",
    "- Function/method names should describe what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad\n",
    "def process_data(x, y, z, w):\n",
    "    result = y * (x - z) - w\n",
    "    return result\n",
    "\n",
    "# Good\n",
    "def calculate_total_payment(base_price, quantity, discount, tax):\n",
    "    total_payment = quantity * (base_price - discount)  - tax\n",
    "    return total_payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type hints\n",
    "\n",
    "- Helps you reason through your code\n",
    "- Don't have to keep track of object types; less mental overhead; self-documenting\n",
    "- They become much more powerful when combined with a linter that checks them e.g., ruff, mypy (catches bugs before they happen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_amino_acid(sequence: str, amino_acid: str = \"A\") -> int:\n",
    "    return sum([1 for aa in sequence if aa == amino_acid])\n",
    "\n",
    "count_amino_acid(sequence=\"CARVAY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "In academia, often you are the only person (aside from possibly a colleague or\n",
    "two) who is ever going to view your code, so writing clean, documented code\n",
    "is going to primarily benefit you.\n",
    "\n",
    "You are your closest collaborator and past you isn’t going\n",
    "to answer any questions present you has forgotten.\n",
    "\n",
    "Do document\n",
    "- Lessons learned or dead ends\n",
    "- Deliberate Design choices\n",
    "- Unintuitive code\n",
    "- High level behavior (inputs/outputs)\n",
    "  \n",
    "Don't document\n",
    "- Low level behavior (implementation details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docstrings\n",
    "\n",
    "```python\n",
    "def function_name(parameters):\n",
    "    \"\"\"\n",
    "    Brief description of the function or method.\n",
    "\n",
    "    More detailed explanation of the function or method's purpose,\n",
    "    input parameters, return values, and any exceptions raised.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    parameters : type\n",
    "        Description of the parameter.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    return_type\n",
    "        Description of what the function or method returns.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    Here, you can provide an example of how to use the function.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "I have found that docstrings are often overkill in the early stages of a project research project when the functions you are writing are changing rapidly because you waste time constantly updating them. Docstrings are better for mature projects when functions won't change often. The issue is that as the code of a function changes the documentation may begin to not reflect the actual behavior of the function (this is called documentation drift). The compiler or your tests will complain at you if your code has a bug, but no error will be raised if your documentation doesn't match the function behavior.\n",
    "\n",
    "I try to keep docstrings minimal and prefer to try and write \"self-documenting\" code. Self-documenting code tends to be simple to read, has clear naming,and benefits from type hints. Self-documenting code is more of an ideal than a reality; eventually, you will have to write comments or docstrings to explain the intricacies of complex projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "Tip: don't say what the code does; say why the code was written the way it was. \n",
    "\n",
    "If you made a conscious design choice for a particular piece of code that is unintuitive, make sure to document it so that your colleagues (or future you) doesn't come back and try to rewrite it only to encounter the same dead ends you have already solved. That being said, if your code is unintuitive, that is often a good indication that it should be simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad\n",
    "def safe_divide(numerator, denominator):\n",
    "    epsilon = 1e-8\n",
    "    # the numerator is divided by the denominator and a small constant\n",
    "    return numerator / (denominator + epsilon)\n",
    "\n",
    "# Good\n",
    "def safe_divide(numerator, denominator):\n",
    "    epsilon = 1e-8\n",
    "    # a small constant is added to the denominator to avoid division by zero\n",
    "    return numerator / (denominator + epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual environments\n",
    "\n",
    "Different projects require different (and often conflicting) dependencies. Virtual environments provide isolation that helps prevent potential conflicts. Helps ensure consistent environments across different machines (somewhat; see Docker containers for a deeper level of isolation).\n",
    "\n",
    "`python3 -m venv .venv`\n",
    "\n",
    "or\n",
    "\n",
    "`conda create --name myenv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use notebooks vs scripts?\n",
    "\n",
    "#### Notebooks\n",
    "\n",
    "Good for: experimenting, visualization, presenting\n",
    "\n",
    "Bad for: complex projects\n",
    "\n",
    "#### Scripts\n",
    "\n",
    "Good for: code that will be reused (hint: most code should be), remote computing\n",
    "\n",
    "Bad for: ?\n",
    "\n",
    "Advantages: \n",
    "- Enforces linear execution of code\n",
    "- Easier to manage variable scope\n",
    "- Often better tooling (linting, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging is easy. No downsides. Only upsides.\n",
    "\n",
    "A very easy packaging tutorial: [link](https://packaging.python.org/en/latest/tutorials/packaging-projects/)\n",
    "\n",
    "- Only takes one small file that you can copy-paste (pyproject.toml) to setup a package\n",
    "- Simplifies importing your code both within a project and between projects\n",
    "- Makes it easier to share your code with others and yourself\n",
    "\n",
    "For example, you can install this package with\n",
    "\n",
    "```bash\n",
    "pip install https://github.com/Elliot-D-Hill/template.git\n",
    "```\n",
    "\n",
    "You can also install in local development (\"editable\") mode where changes to the codes are automatically reflected in the program's behavior\n",
    "\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Once installed, you no longer have to manipulate the PYTHONPATH (which you shouldn't do anyway) to import modules, just import them like this\n",
    "\n",
    "```python\n",
    "from example.model import MyNetwork\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project structure\n",
    "\n",
    "This repository follows a common format for python projects.\n",
    "\n",
    "```bash\n",
    ".\n",
    "├── LICENSE                 # Who can use your project and how.\n",
    "├── README.md               # Help background, setup, and basic usage of your software\n",
    "├── .gitignore              # Determines which files will not be tracked by git\n",
    "├── config.toml             # Consolidates variables that affect program behavior\n",
    "├── data                    # Stores data (added to .gitignore)\n",
    "├── log.ipynb               # The sandbox\n",
    "├── pyproject.toml          # Used for packaging\n",
    "├── requirements.txt        # Project dependencies are listed here\n",
    "├── src                     # Package source code\n",
    "│   └── example\n",
    "│       ├── __init__.py\n",
    "│       ├── __main__.py\n",
    "│       ├── config.py\n",
    "│       ├── dataset.py\n",
    "│       └── model.py\n",
    "└── tests                   # Unit tests that test the source code\n",
    "    ├── test_dataset.py\n",
    "    └── test_model.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you write your own code vs import from a package?\n",
    "\n",
    "- If a package has the functionality you need\n",
    "- If the package is trusted (high star count on GitHub is a good indicator)\n",
    "\n",
    "Benefits of using other people's code:\n",
    "- Good packages write tests for their code (you probably don't)\n",
    "- Popular packages are used, tested, and reviewed informally by their users every day (raises our confidence in them)\n",
    "- Adopting other peoples code let's you get to your research problem faster. As a researcher, we often only change one or two aspects of a method/model/algorithm for a given project. That means that we can save a lot of time by importing as many of the parts we are not customizing as possible. \n",
    "\n",
    "Example:\n",
    "\n",
    "Your project is to design a custom loss function. You probably want to avoid also writing your optimizer and model architecture from scratch. You probably want to reuse standard model architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When should you optimize your code?\n",
    "\n",
    "- Only when you need to\n",
    "- When it is free/easy to do; doesn't take a lot of time or add a lot of tech dept\n",
    "- If you must optimize your code, focus on bottlenecks first; find bottlenecks via code profilers e.g., cProfile in Python\n",
    "- If you want to learn how to write optimized code\n",
    "\n",
    "Performance optimization is typically the last part of your code you want\n",
    "to improve. This is because optimizations are often time consuming to\n",
    "implement and can introduce substantial code complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration files\n",
    "\n",
    "Consolidates parameters into fewer places. \n",
    "\n",
    "Avoids having to touch the source code (and possibly introduce new bugs) to change program behavior. \n",
    "\n",
    "By having all tunable parameters in one place, it makes it easy to make your methods section of your paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write modular code\n",
    "A good rule of thumb: functions and classes should have roughly one responsibility\n",
    "\n",
    "Modular code is easier to read, reuse, reason through, debug, and write tests for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad\n",
    "def process_data(data):\n",
    "    # Responsibility 1: Calculate average\n",
    "    total = sum(data)\n",
    "    average = total / len(data)\n",
    "    # Responsibility 2: Filter outliers\n",
    "    outliers = [x for x in data if x >= 2 * average]\n",
    "    # Responsibility 3: Generate a report\n",
    "    n = len(data)\n",
    "    report = f\"Average: {average}, Total data points: {n}, Outliers removed: {n - len(outliers)}\"\n",
    "    return outliers, report\n",
    "\n",
    "# Good\n",
    "def calculate_average(data):\n",
    "    total = sum(data)\n",
    "    return total / len(data)\n",
    "\n",
    "def filter_outliers(data, average):\n",
    "    return [x for x in data if x >= 2 * average]\n",
    "\n",
    "def generate_report(data, outliers_removed):\n",
    "    n = len(data)\n",
    "    return f\"Average: {calculate_average(data)}, Total data points: {n}, Outliers removed: {n - len(outliers_removed)}\"\n",
    "\n",
    "def process_data(data):\n",
    "    average = calculate_average(data)\n",
    "    outliers_removed = filter_outliers(data, average)\n",
    "    report = generate_report(data, outliers_removed)\n",
    "    return outliers_removed, report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit tests\n",
    "\n",
    "- Automates manual testing\n",
    "  - We often rerun our code over and over to check it's behavior, but this becomes tedious if you need to check multiple parts of the code at once. Unit tests automates this.\n",
    "- Allows you to refactor fearlessly\n",
    "  - If you change the code, unit tests will highlight which parts of the code your changes are affecting. Once you pass all of the unit tests, you can be more confident that the current version is behaving like the previous version.\n",
    "- It's likely that you are already unknowingly writing them\n",
    "  - Often, when we write a new function, we will generate some toy data to manually test it. Then, we discard the toy example after we are satisfied with the result. But the toy example's usefulness doesn't end there; we can make it a unit test and it will help our code forever more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from polars.testing import assert_frame_equal\n",
    "\n",
    "def make_adhd_phenotype(codes: str) -> pl.Expr:\n",
    "    \"\"\"\n",
    "    ADHD phenotype = any patient who has two or more ADHD ICD10 codes in their medical history\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pl.col(\"event\")\n",
    "        .str.contains(codes)\n",
    "        .sum()\n",
    "        .ge(2)\n",
    "        .over(\"mrn\")\n",
    "        .cast(pl.Int64)\n",
    "        .alias(\"adhd\")\n",
    "    )\n",
    "\n",
    "def test_make_adhd_phenotype():\n",
    "    df = pl.DataFrame(\n",
    "        {\n",
    "            \"mrn\": [\"x\", \"x\", \"x\", \"y\", \"y\", \"z\", \"z\", \"z\"],\n",
    "            \"event\": [\"a\", \"b\", \"b\", \"a\", \"c\", \"a\", \"c\", \"b\"],\n",
    "        }\n",
    "    )\n",
    "    expected = pl.DataFrame({\"adhd\": [0, 0, 0, 1, 1, 1, 1, 1]})\n",
    "    phenotype = make_adhd_phenotype(codes=\"a|c\")\n",
    "    result = df.select(phenotype)\n",
    "    assert_frame_equal(expected, result)\n",
    "\n",
    "test_make_adhd_phenotype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how much testings is enough? No matter how many tests you write you will never prove your code will work 100% of the time, but (in a Bayesian sense) you will grow more and more confident that your code behaves as expected as you add more tests. Therefore, you should write as many tests as you need to be confident that your code works. Sometimes this is a lot of tests. Sometimes this is no tests.\n",
    "\n",
    "That amount of tests should scale with how catastrophic failure is; NASA needs to write more tests than you do.\n",
    "\n",
    "- \"Happy path\" testing: well formatted input, expected output\n",
    "- \"Sad path\" testing: tests if your code handle errors or unexpected input gracefully\n",
    "- Edge cases: tests uncommon (though still valid) input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style (Warning: you have entered the Opinion Zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefer simple to clever code\n",
    "\n",
    "There is always a temptation to write abstract, generalized code, but for most tasks, the correctness of the program is more important than it's design . Simple code is easier to read, write, modify, and, validate than clever code, therefore prefer simple code. That being said, sometimes clever code is also simpler, so it often comes down to a judgment call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a case where it's not clear if clever or simple is better since the clever solution is also simple\n",
    "\n",
    "# Clever\n",
    "def factorial(n):\n",
    "    return 1 if n == 0 else n * factorial(n - 1)\n",
    "\n",
    "# Simple\n",
    "def factorial(n):\n",
    "    result = 1\n",
    "    for i in range(1, n + 1):\n",
    "        result *= i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefer explicit to implicit code\n",
    "\n",
    "For example, I would often run into bugs where I would give function arguments in the wrong order. By explicitly naming the argument this type of bug is completely avoided. The few extra keystrokes are a lot faster than the time it takes to detect and fix these types of bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "\n",
    "matrix = torch.rand(size=(5, 5))\n",
    "vector = torch.rand(size=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2822, 0.9028, 0.6050, 1.2608, 1.6850])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bad: you risk giving the arguments in the wrong order which can lead of subtle bugs\n",
    "torch.matmul(matrix, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0190, 0.9451, 0.8814, 1.3270, 0.9387])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accidentally swapping the arguments leads to different results, but no error was raised; detecting this bug could be tricky\n",
    "torch.matmul(vector, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2822, 0.9028, 0.6050, 1.2608, 1.6850])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good: explicitly naming the arguments prevents this bug\n",
    "torch.matmul(input=matrix, other=vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Avoid \"magic\" variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad\n",
    "def calculate_area():\n",
    "    return 3.14159 * 5 * 5\n",
    "\n",
    "# Good\n",
    "PI: float = 3.14159\n",
    "def calculate_area(radius: float | int):\n",
    "    area = PI * radius * radius\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think about big-O a little (under construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
